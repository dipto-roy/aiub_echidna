#!/usr/bin/env python3
"""
Enhanced Novel Vulnerability Discovery Analysis Tool
Advanced pattern recognition and vulnerability classification
"""

import json
import re
import os
import sys
from collections import defaultdict, Counter
from dataclasses import dataclass
from typing import List, Dict, Tuple, Set, Optional
from pathlib import Path
import hashlib

@dataclass
class EnhancedVulnerabilityPattern:
    """Enhanced vulnerability pattern with detailed analysis"""
    pattern_id: str
    pattern_type: str
    attack_vector: str
    call_sequence: List[str]
    function_interactions: Dict[str, int]
    failed_properties: List[str]
    gas_patterns: Dict[str, List[int]]
    time_manipulation: Dict[str, int]
    address_patterns: Dict[str, List[str]]
    value_patterns: List[str]
    complexity_score: float
    novelty_score: float
    severity: str
    impact_assessment: str
    attack_scenario: str
    mitigation_suggestions: List[str]
    
class EnhancedVulnerabilityAnalyzer:
    """Advanced analyzer for novel vulnerability discovery"""
    
    def __init__(self, echidna_output_dir: str):
        self.output_dir = Path(echidna_output_dir)
        self.patterns = []
        self.known_attack_patterns = self._load_known_attack_patterns()
        
    def _load_known_attack_patterns(self) -> Dict[str, Set[str]]:
        """Load comprehensive known attack pattern database"""
        return {
            'reentrancy': {'call', 'transfer', 'send', 'call'},
            'flash_loan': {'flashLoan', 'deposit', 'withdraw', 'swap'},
            'price_manipulation': {'swap', 'addLiquidity', 'removeLiquidity', 'getPrice'},
            'sandwich_attack': {'swap', 'frontrun', 'backrun'},
            'governance_attack': {'propose', 'vote', 'execute', 'delegate'},
            'oracle_manipulation': {'updatePrice', 'getPrice', 'setPrice'},
            'access_control': {'mint', 'burn', 'pause', 'changeOwner'},
            'integer_overflow': {'add', 'mul', 'transfer', 'approve'},
            'dos_gas': {'loop', 'array', 'mapping', 'storage'},
            'timestamp_dependency': {'block.timestamp', 'now', 'timelock'}
        }
    
    def analyze_comprehensive(self) -> List[EnhancedVulnerabilityPattern]:
        """Comprehensive vulnerability pattern analysis"""
        print("🔬 Starting Enhanced Vulnerability Discovery Analysis...")
        
        # Parse all available data
        reproducers = self._parse_enhanced_reproducers()
        if not reproducers:
            print("⚠️  No reproducers found for analysis")
            return []
            
        # Perform multi-dimensional analysis
        patterns = []
        
        # 1. Sequence-based pattern analysis
        sequence_patterns = self._analyze_call_sequences(reproducers)
        patterns.extend(sequence_patterns)
        
        # 2. Temporal pattern analysis
        temporal_patterns = self._analyze_temporal_patterns(reproducers)
        patterns.extend(temporal_patterns)
        
        # 3. Cross-functional interaction analysis
        interaction_patterns = self._analyze_cross_functional_interactions(reproducers)
        patterns.extend(interaction_patterns)
        
        # 4. Economic/value flow analysis
        economic_patterns = self._analyze_economic_patterns(reproducers)
        patterns.extend(economic_patterns)
        
        # Remove duplicates and rank
        unique_patterns = self._deduplicate_patterns(patterns)
        ranked_patterns = self._rank_by_novelty_and_severity(unique_patterns)
        
        self.patterns = ranked_patterns
        return ranked_patterns
    
    def _parse_enhanced_reproducers(self) -> List[Dict]:
        """Enhanced reproducer parsing with detailed extraction"""
        reproducers = []
        
        possible_dirs = [
            self.output_dir / "reproducers",
            self.output_dir / "reproducers-unshrunk", 
            self.output_dir
        ]
        
        for reproducer_dir in possible_dirs:
            if not reproducer_dir.exists():
                continue
                
            for file_path in reproducer_dir.glob("*.txt"):
                try:
                    with open(file_path, 'r') as f:
                        content = f.read()
                        reproducer = self._parse_enhanced_reproducer_content(content)
                        if reproducer:
                            reproducer['source_file'] = str(file_path)
                            reproducer['file_hash'] = hashlib.md5(content.encode()).hexdigest()
                            reproducers.append(reproducer)
                except Exception as e:
                    print(f"⚠️  Error parsing {file_path}: {e}")
        
        print(f"📄 Parsed {len(reproducers)} enhanced reproducer files")
        return reproducers
    
    def _parse_enhanced_reproducer_content(self, content: str) -> Optional[Dict]:
        """Enhanced parsing with detailed extraction"""
        try:
            calls_data = json.loads(content.strip())
            if not isinstance(calls_data, list):
                return None
                
            reproducer = {
                'call_sequence': [],
                'function_calls': [],
                'addresses': [],
                'values': [],
                'gas_usage': [],
                'time_delays': [],
                'value_flows': [],
                'address_interactions': defaultdict(list),
                'function_parameters': defaultdict(list),
                'transaction_count': len(calls_data)
            }
            
            for i, call_data in enumerate(calls_data):
                if 'call' not in call_data:
                    continue
                    
                call_info = call_data['call']
                if 'contents' not in call_info or len(call_info['contents']) < 1:
                    continue
                    
                function_name = call_info['contents'][0]
                params = call_info['contents'][1] if len(call_info['contents']) > 1 else []
                
                reproducer['call_sequence'].append(function_name)
                reproducer['function_calls'].append({
                    'index': i,
                    'function': function_name,
                    'params': params,
                    'raw_call': call_info
                })
                
                # Enhanced data extraction
                if 'gas' in call_data:
                    reproducer['gas_usage'].append(call_data['gas'])
                
                if 'delay' in call_data and call_data['delay']:
                    delay_val = call_data['delay'][0] if isinstance(call_data['delay'], list) else call_data['delay']
                    if isinstance(delay_val, str):
                        delay_int = int(delay_val, 16) if delay_val.startswith('0x') else int(delay_val)
                        reproducer['time_delays'].append(delay_int)
                
                if 'src' in call_data:
                    src_addr = call_data['src']
                    reproducer['addresses'].append(src_addr)
                    reproducer['address_interactions'][src_addr].append(function_name)
                
                if 'dst' in call_data:
                    dst_addr = call_data['dst']
                    reproducer['addresses'].append(dst_addr)
                    reproducer['address_interactions'][dst_addr].append(function_name)
                
                if 'value' in call_data:
                    value = call_data['value']
                    reproducer['values'].append(value)
                    reproducer['value_flows'].append({
                        'function': function_name,
                        'value': value,
                        'src': call_data.get('src'),
                        'dst': call_data.get('dst')
                    })
                
                # Store function parameters for pattern analysis
                reproducer['function_parameters'][function_name].append(params)
            
            return reproducer if reproducer['call_sequence'] else None
            
        except Exception as e:
            print(f"⚠️  Enhanced parsing error: {e}")
            return None
    
    def _analyze_call_sequences(self, reproducers: List[Dict]) -> List[EnhancedVulnerabilityPattern]:
        """Analyze call sequence patterns for novel attack vectors"""
        patterns = []
        
        # Group by function combinations
        function_combinations = defaultdict(list)
        for reproducer in reproducers:
            func_set = frozenset(reproducer['call_sequence'])
            function_combinations[func_set].append(reproducer)
        
        for func_combo, group in function_combinations.items():
            if len(group) < 1:  # Need at least one instance
                continue
                
            pattern = self._create_sequence_pattern(func_combo, group)
            if pattern:
                patterns.append(pattern)
        
        return patterns
    
    def _create_sequence_pattern(self, functions: frozenset, reproducers: List[Dict]) -> Optional[EnhancedVulnerabilityPattern]:
        """Create enhanced pattern from sequence analysis"""
        
        # Calculate complexity and novelty scores
        complexity_score = self._calculate_complexity_score(functions, reproducers)
        novelty_score = self._calculate_novelty_score(functions)
        
        if novelty_score < 0.3:  # Skip known patterns
            return None
        
        # Determine pattern type and attack vector
        pattern_type = self._classify_attack_pattern(functions, reproducers)
        attack_vector = self._determine_attack_vector(functions, reproducers)
        
        # Generate comprehensive analysis
        impact_assessment = self._assess_impact(functions, reproducers)
        attack_scenario = self._generate_attack_scenario(functions, reproducers)
        mitigation_suggestions = self._suggest_mitigations(pattern_type, functions)
        
        # Aggregate data
        all_calls = []
        all_gas = []
        all_delays = []
        all_addresses = []
        all_values = []
        
        for r in reproducers:
            all_calls.extend(r['call_sequence'])
            all_gas.extend(r['gas_usage'])
            all_delays.extend(r['time_delays'])
            all_addresses.extend(r['addresses'])
            all_values.extend(r['values'])
        
        pattern_id = f"enhanced_{pattern_type}_{hashlib.md5(str(sorted(functions)).encode()).hexdigest()[:8]}"
        
        return EnhancedVulnerabilityPattern(
            pattern_id=pattern_id,
            pattern_type=pattern_type,
            attack_vector=attack_vector,
            call_sequence=list(functions),
            function_interactions=Counter(all_calls),
            failed_properties=["property_violation"],  # Would extract from logs
            gas_patterns={"usage": all_gas},
            time_manipulation={"delays": all_delays},
            address_patterns={"interactions": list(set(all_addresses))},
            value_patterns=all_values,
            complexity_score=complexity_score,
            novelty_score=novelty_score,
            severity=self._determine_severity(pattern_type, complexity_score),
            impact_assessment=impact_assessment,
            attack_scenario=attack_scenario,
            mitigation_suggestions=mitigation_suggestions
        )
    
    def _calculate_complexity_score(self, functions: frozenset, reproducers: List[Dict]) -> float:
        """Calculate attack complexity score"""
        score = 0.0
        
        # Function diversity
        score += len(functions) * 0.1
        
        # Cross-functional interactions
        defi_functions = {'addLiquidity', 'swap', 'removeLiquidity'}
        transfer_functions = {'transfer', 'complexTransfer', 'transferFrom'}
        admin_functions = {'mint', 'burn', 'pause', 'setOwner'}
        
        categories = 0
        if functions & defi_functions:
            categories += 1
        if functions & transfer_functions:
            categories += 1
        if functions & admin_functions:
            categories += 1
        
        score += categories * 0.2
        
        # Time complexity
        total_delays = sum(len(r['time_delays']) for r in reproducers)
        score += min(total_delays * 0.01, 0.3)
        
        # Transaction count complexity  
        avg_tx_count = sum(r['transaction_count'] for r in reproducers) / len(reproducers)
        score += min(avg_tx_count * 0.02, 0.2)
        
        return min(score, 1.0)
    
    def _calculate_novelty_score(self, functions: frozenset) -> float:
        """Calculate novelty score against known patterns"""
        max_similarity = 0.0
        
        for known_pattern, known_functions in self.known_attack_patterns.items():
            similarity = len(functions & known_functions) / len(functions | known_functions)
            max_similarity = max(max_similarity, similarity)
        
        return 1.0 - max_similarity
    
    def _classify_attack_pattern(self, functions: frozenset, reproducers: List[Dict]) -> str:
        """Classify the type of attack pattern"""
        
        if 'complexTransfer' in functions:
            if {'addLiquidity', 'swap'} & functions:
                return "hybrid_defi_transfer_manipulation"
            else:
                return "complex_transfer_exploitation"
        
        if {'addLiquidity', 'swap'} <= functions:
            return "defi_liquidity_manipulation"
        
        # Check for temporal patterns
        max_delays = []
        for r in reproducers:
            if r['time_delays']:
                max_delays.append(max(r['time_delays']))
        
        if max_delays and max(max_delays) > 100000:
            return "temporal_logic_exploitation"
        
        if len(functions) > 5:
            return "multi_vector_complex_attack"
        
        return "unknown_novel_pattern"
    
    def _determine_attack_vector(self, functions: frozenset, reproducers: List[Dict]) -> str:
        """Determine the primary attack vector"""
        
        vectors = []
        
        if 'complexTransfer' in functions:
            vectors.append("Complex token transfer manipulation")
        
        if {'addLiquidity', 'swap'} & functions:
            vectors.append("DeFi liquidity pool exploitation")
        
        # Check for value manipulation
        for r in reproducers:
            extreme_values = [v for v in r['values'] if 'ff' in str(v).lower()]
            if extreme_values:
                vectors.append("Extreme value injection")
                break
        
        # Check for time manipulation
        for r in reproducers:
            if r['time_delays'] and max(r['time_delays']) > 50000:
                vectors.append("Temporal logic bypass")
                break
        
        return " + ".join(vectors) if vectors else "Unknown attack vector"
    
    def _assess_impact(self, functions: frozenset, reproducers: List[Dict]) -> str:
        """Assess the potential impact of the vulnerability"""
        
        impacts = []
        
        if 'complexTransfer' in functions:
            impacts.append("Unauthorized token movements")
        
        if {'addLiquidity', 'swap'} & functions:
            impacts.append("DeFi protocol fund drainage")
        
        if any(len(r['addresses']) > 5 for r in reproducers):
            impacts.append("Multi-account state corruption")
        
        if any(r['time_delays'] and max(r['time_delays']) > 100000 for r in reproducers):
            impacts.append("Temporal invariant violations")
        
        return " | ".join(impacts) if impacts else "State inconsistency"
    
    def _generate_attack_scenario(self, functions: frozenset, reproducers: List[Dict]) -> str:
        """Generate human-readable attack scenario"""
        
        scenario_parts = []
        
        if 'complexTransfer' in functions:
            scenario_parts.append("1. Attacker initiates complex transfer operations")
        
        if 'addLiquidity' in functions:
            scenario_parts.append("2. Manipulates liquidity pool state")
        
        if 'swap' in functions:
            scenario_parts.append("3. Executes swap operations to extract value")
        
        # Check for time components
        if any(r['time_delays'] for r in reproducers):
            scenario_parts.append("4. Uses strategic time delays to bypass checks")
        
        scenario_parts.append("5. Achieves property violation and potential fund extraction")
        
        return " → ".join(scenario_parts)
    
    def _suggest_mitigations(self, pattern_type: str, functions: frozenset) -> List[str]:
        """Suggest specific mitigation strategies"""
        
        mitigations = []
        
        if "transfer" in pattern_type:
            mitigations.append("Implement reentrancy guards on all transfer functions")
            mitigations.append("Add state consistency checks after transfers")
        
        if "defi" in pattern_type:
            mitigations.append("Implement slippage protection mechanisms")
            mitigations.append("Add liquidity manipulation detection")
        
        if "temporal" in pattern_type:
            mitigations.append("Remove time-dependent logic from critical functions")
            mitigations.append("Use block numbers instead of timestamps")
        
        mitigations.append("Add comprehensive state invariant checks")
        mitigations.append("Implement emergency pause mechanisms")
        
        return mitigations
    
    def _determine_severity(self, pattern_type: str, complexity_score: float) -> str:
        """Determine severity based on pattern analysis"""
        
        if "defi" in pattern_type or "transfer" in pattern_type:
            return "CRITICAL"
        elif complexity_score > 0.7:
            return "HIGH"
        elif complexity_score > 0.4:
            return "MEDIUM"
        else:
            return "LOW"
    
    def _analyze_temporal_patterns(self, reproducers: List[Dict]) -> List[EnhancedVulnerabilityPattern]:
        """Analyze temporal-specific vulnerability patterns"""
        # Implementation for temporal pattern analysis
        return []
    
    def _analyze_cross_functional_interactions(self, reproducers: List[Dict]) -> List[EnhancedVulnerabilityPattern]:
        """Analyze cross-functional interaction patterns"""
        # Implementation for cross-functional analysis
        return []
    
    def _analyze_economic_patterns(self, reproducers: List[Dict]) -> List[EnhancedVulnerabilityPattern]:
        """Analyze economic/value flow patterns"""
        # Implementation for economic pattern analysis
        return []
    
    def _deduplicate_patterns(self, patterns: List[EnhancedVulnerabilityPattern]) -> List[EnhancedVulnerabilityPattern]:
        """Remove duplicate patterns"""
        seen_ids = set()
        unique_patterns = []
        
        for pattern in patterns:
            if pattern.pattern_id not in seen_ids:
                seen_ids.add(pattern.pattern_id)
                unique_patterns.append(pattern)
        
        return unique_patterns
    
    def _rank_by_novelty_and_severity(self, patterns: List[EnhancedVulnerabilityPattern]) -> List[EnhancedVulnerabilityPattern]:
        """Rank patterns by novelty and severity"""
        
        severity_weights = {"CRITICAL": 4, "HIGH": 3, "MEDIUM": 2, "LOW": 1}
        
        def ranking_score(pattern):
            severity_score = severity_weights.get(pattern.severity, 1)
            return (pattern.novelty_score * 0.4 + 
                   pattern.complexity_score * 0.3 + 
                   severity_score * 0.3)
        
        return sorted(patterns, key=ranking_score, reverse=True)
    
    def generate_enhanced_report(self, output_file: str = None):
        """Generate comprehensive vulnerability discovery report"""
        if not output_file:
            output_file = self.output_dir / "enhanced_vulnerability_report.md"
        
        report_content = self._create_enhanced_report_content()
        
        with open(output_file, 'w') as f:
            f.write(report_content)
        
        print(f"📊 Enhanced report saved to: {output_file}")
    
    def _create_enhanced_report_content(self) -> str:
        """Create detailed report content"""
        
        if not self.patterns:
            return "# Enhanced Vulnerability Discovery Report\n\n⚠️ No vulnerability patterns discovered."
        
        content = []
        content.append("# Enhanced Novel Vulnerability Discovery Report")
        content.append(f"Generated on: {self.output_dir}")
        content.append("")
        
        # Executive Summary
        content.append("## Executive Summary")
        critical_count = sum(1 for p in self.patterns if p.severity == "CRITICAL")
        high_count = sum(1 for p in self.patterns if p.severity == "HIGH")
        
        content.append(f"- **Total Novel Patterns**: {len(self.patterns)}")
        content.append(f"- **CRITICAL**: {critical_count}")
        content.append(f"- **HIGH**: {high_count}")
        content.append("")
        
        # Detailed findings
        content.append("## Detailed Vulnerability Patterns")
        
        for i, pattern in enumerate(self.patterns, 1):
            content.append(f"### {i}. {pattern.pattern_type.replace('_', ' ').title()}")
            content.append(f"**Pattern ID**: `{pattern.pattern_id}`")
            content.append(f"**Severity**: {pattern.severity}")
            content.append(f"**Novelty Score**: {pattern.novelty_score:.2f}")
            content.append(f"**Complexity Score**: {pattern.complexity_score:.2f}")
            content.append(f"**Attack Vector**: {pattern.attack_vector}")
            content.append("")
            content.append(f"**Impact Assessment**: {pattern.impact_assessment}")
            content.append("")
            content.append("**Attack Scenario**:")
            content.append(pattern.attack_scenario)
            content.append("")
            content.append("**Mitigation Suggestions**:")
            for mitigation in pattern.mitigation_suggestions:
                content.append(f"- {mitigation}")
            content.append("")
            content.append("---")
            content.append("")
        
        return "\n".join(content)

def main():
    if len(sys.argv) != 2:
        print("Usage: python enhanced_vulnerability_discovery.py <echidna_output_directory>")
        print("Example: python enhanced_vulnerability_discovery.py ./corpus")
        sys.exit(1)
    
    output_dir = sys.argv[1]
    analyzer = EnhancedVulnerabilityAnalyzer(output_dir)
    
    patterns = analyzer.analyze_comprehensive()
    
    if patterns:
        print(f"🎯 Discovered {len(patterns)} novel vulnerability patterns")
        analyzer.generate_enhanced_report()
        
        # Print summary
        for pattern in patterns:
            print(f"🔍 {pattern.pattern_type}: {pattern.attack_vector} ({pattern.severity})")
    else:
        print("⚠️ No novel vulnerability patterns discovered")

if __name__ == "__main__":
    main()
