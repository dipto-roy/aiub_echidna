#!/usr/bin/env python3
"""
Novel Vulnerability Discovery Analysis Tool
Analyzes Echidna fuzzing results to identify potential new vulnerability classes
"""

import json
import re
import os
import sys
from collections import defaultdict, Counter
from dataclasses import dataclass
from typing import List, Dict, Tuple, Set
from pathlib import Path

@dataclass
class VulnerabilityPattern:
    """Represents a discovered vulnerability pattern"""
    pattern_id: str
    call_sequence: List[str]
    failed_properties: List[str]
    gas_consumption: List[int]
    time_delays: List[int]
    state_changes: Dict[str, str]
    frequency: int
    severity: str
    description: str

class VulnerabilityDiscoveryAnalyzer:
    """Main analyzer for discovering novel vulnerability patterns"""
    
    def __init__(self, echidna_output_dir: str):
        self.output_dir = Path(echidna_output_dir)
        self.patterns = []
        self.known_vulns = self._load_known_vulnerabilities()
        
    def _load_known_vulnerabilities(self) -> Set[str]:
        """Load known vulnerability patterns for novelty assessment"""
        return {
            "reentrancy", "overflow", "underflow", "timestamp_dependency",
            "tx_origin", "delegatecall", "unchecked_call", "dos_gas_limit",
            "price_manipulation", "flash_loan_attack", "sandwich_attack"
        }
    
    def analyze_echidna_results(self) -> List[VulnerabilityPattern]:
        """Main analysis function"""
        print("üîç Analyzing Echidna results for novel vulnerability patterns...")
        
        # Parse reproducers and coverage data
        reproducers = self._parse_reproducers()
        coverage_data = self._parse_coverage()
        gas_data = self._extract_gas_patterns()
        
        # Identify patterns
        patterns = self._identify_patterns(reproducers, coverage_data, gas_data)
        
        # Assess novelty
        novel_patterns = self._assess_novelty(patterns)
        
        # Rank by severity and impact
        ranked_patterns = self._rank_patterns(novel_patterns)
        
        self.patterns = ranked_patterns
        return ranked_patterns
    
    def _parse_reproducers(self) -> List[Dict]:
        """Parse Echidna reproducer files"""
        reproducers = []
        
        # Check multiple possible reproducer directories
        possible_dirs = [
            self.output_dir / "reproducers",
            self.output_dir / "reproducers-unshrunk",
            self.output_dir  # If we're pointing directly at a reproducer directory
        ]
        
        for reproducer_dir in possible_dirs:
            if not reproducer_dir.exists():
                continue
                
            print(f"üîç Checking reproducer directory: {reproducer_dir}")
            
            for file_path in reproducer_dir.glob("*.txt"):
                try:
                    with open(file_path, 'r') as f:
                        content = f.read()
                        reproducer = self._parse_reproducer_content(content)
                        if reproducer:
                            reproducer['source_file'] = str(file_path)
                            reproducers.append(reproducer)
                except Exception as e:
                    print(f"‚ö†Ô∏è  Error parsing {file_path}: {e}")
        
        print(f"üìÑ Parsed {len(reproducers)} reproducer files")
        return reproducers
    
    def _parse_reproducer_content(self, content: str) -> Dict:
        """Parse individual reproducer file content (JSON format from Echidna)"""
        try:
            # Parse JSON array of transaction calls
            calls_data = json.loads(content.strip())
            if not isinstance(calls_data, list):
                return None
                
            reproducer = {
                'call_sequence': [],
                'failed_property': 'property_violation',  # Will be inferred from patterns
                'gas_usage': [],
                'time_delays': [],
                'function_calls': [],
                'addresses': set(),
                'values': []
            }
            
            for call_data in calls_data:
                if 'call' in call_data:
                    call_info = call_data['call']
                    if 'contents' in call_info and len(call_info['contents']) >= 2:
                        function_name = call_info['contents'][0]
                        params = call_info['contents'][1] if len(call_info['contents']) > 1 else []
                        
                        reproducer['call_sequence'].append(function_name)
                        reproducer['function_calls'].append({
                            'function': function_name,
                            'params': params
                        })
                        
                        # Extract gas info
                        if 'gas' in call_data:
                            reproducer['gas_usage'].append(call_data['gas'])
                        
                        # Extract time delays
                        if 'delay' in call_data and call_data['delay']:
                            delay_val = call_data['delay'][0] if isinstance(call_data['delay'], list) else call_data['delay']
                            if isinstance(delay_val, str):
                                delay_int = int(delay_val, 16) if delay_val.startswith('0x') else int(delay_val)
                                reproducer['time_delays'].append(delay_int)
                        
                        # Extract addresses for pattern analysis
                        if 'src' in call_data:
                            reproducer['addresses'].add(call_data['src'])
                        if 'dst' in call_data:
                            reproducer['addresses'].add(call_data['dst'])
                        
                        # Extract values
                        if 'value' in call_data:
                            reproducer['values'].append(call_data['value'])
            
            return reproducer if reproducer['call_sequence'] else None
            
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            print(f"‚ö†Ô∏è  Error parsing JSON reproducer: {e}")
            return None
    
    def _parse_coverage(self) -> Dict:
        """Parse coverage data from Echidna output"""
        coverage_data = {}
        coverage_dir = self.output_dir / "coverage"
        
        if not coverage_dir.exists():
            return coverage_data
            
        for file_path in coverage_dir.glob("*.txt"):
            try:
                with open(file_path, 'r') as f:
                    content = f.read()
                    # Extract coverage metrics
                    coverage_info = self._extract_coverage_metrics(content)
                    coverage_data[file_path.name] = coverage_info
            except Exception as e:
                print(f"‚ö†Ô∏è  Error parsing coverage {file_path}: {e}")
                
        return coverage_data
    
    def _extract_coverage_metrics(self, content: str) -> Dict:
        """Extract coverage metrics from coverage file"""
        metrics = {
            'covered_lines': 0,
            'total_lines': 0,
            'coverage_percentage': 0.0,
            'uncovered_critical_paths': []
        }
        
        lines = content.split('\n')
        for line in lines:
            if '|' in line and ('*' in line or '#' in line):
                # This is a coverage line
                if '*' in line:
                    metrics['covered_lines'] += 1
                metrics['total_lines'] += 1
                
                # Check for critical uncovered paths
                if '#' in line and any(keyword in line.lower() for keyword in 
                                    ['transfer', 'approve', 'mint', 'burn', 'emergency']):
                    metrics['uncovered_critical_paths'].append(line.strip())
        
        if metrics['total_lines'] > 0:
            metrics['coverage_percentage'] = metrics['covered_lines'] / metrics['total_lines'] * 100
            
        return metrics
    
    def _extract_gas_patterns(self) -> Dict:
        """Extract gas consumption patterns from Echidna logs"""
        gas_patterns = defaultdict(list)
        
        # This would parse actual Echidna logs for gas information
        # For now, returning mock data structure
        return {
            'function_gas_usage': defaultdict(list),
            'anomalous_gas_spikes': [],
            'gas_optimization_opportunities': []
        }
    
    def _identify_patterns(self, reproducers: List[Dict], coverage_data: Dict, gas_data: Dict) -> List[VulnerabilityPattern]:
        """Identify vulnerability patterns from the data"""
        patterns = []
        
        # Group reproducers by failed property
        property_groups = defaultdict(list)
        for reproducer in reproducers:
            if reproducer['failed_property']:
                property_groups[reproducer['failed_property']].append(reproducer)
        
        # Analyze each group for patterns
        for property_name, group in property_groups.items():
            pattern = self._analyze_property_group(property_name, group)
            if pattern:
                patterns.append(pattern)
        
        # Look for cross-property patterns
        cross_patterns = self._find_cross_property_patterns(reproducers)
        patterns.extend(cross_patterns)
        
        return patterns
    
    def _analyze_property_group(self, property_name: str, reproducers: List[Dict]) -> VulnerabilityPattern:
        """Analyze a group of reproducers for the same failed property"""
        
        # Find common call sequences
        all_sequences = [r['call_sequence'] for r in reproducers]
        common_patterns = self._find_common_subsequences(all_sequences)
        
        # Analyze function call patterns
        all_functions = []
        all_addresses = set()
        time_delays = []
        gas_usage = []
        
        for r in reproducers:
            all_functions.extend(r['call_sequence'])
            all_addresses.update(r['addresses'])
            time_delays.extend(r['time_delays'])
            gas_usage.extend(r['gas_usage'])
        
        # Identify specific patterns based on function combinations
        pattern_type = self._classify_pattern_type(all_functions, reproducers)
        
        # Create pattern description
        description = self._generate_pattern_description(property_name, all_functions, time_delays, pattern_type)
        
        # Assess severity based on function types and complexity
        severity = self._assess_severity(property_name, all_functions, len(reproducers))
        
        pattern = VulnerabilityPattern(
            pattern_id=f"pattern_{property_name}_{pattern_type}_{len(reproducers)}",
            call_sequence=common_patterns[0] if common_patterns else list(set(all_functions)),
            failed_properties=[property_name],
            gas_consumption=gas_usage,
            time_delays=time_delays,
            state_changes=self._extract_state_changes(reproducers),
            frequency=len(reproducers),
            severity=severity,
            description=description
        )
        
        return pattern
    
    def _classify_pattern_type(self, functions: List[str], reproducers: List[Dict]) -> str:
        """Classify the type of vulnerability pattern based on function calls"""
        function_set = set(functions)
        
        # Complex transfer patterns
        if 'complexTransfer' in function_set:
            return "complex_transfer_manipulation"
        
        # Economic/DeFi patterns
        if {'addLiquidity', 'swap'}.issubset(function_set):
            return "defi_liquidity_manipulation"
        
        # Temporal patterns (time-based)
        max_delays = []
        for r in reproducers:
            if r['time_delays']:
                max_delays.append(max(r['time_delays']))
        
        if max_delays and max(max_delays) > 100000:  # Significant time delays
            return "temporal_logic_exploit"
        
        # State corruption patterns
        if len(function_set) > 5:  # Complex interaction patterns
            return "state_corruption_sequence"
        
        return "unknown_pattern"
    
    def _extract_state_changes(self, reproducers: List[Dict]) -> Dict[str, str]:
        """Extract state change information from reproducers"""
        state_changes = {}
        
        for r in reproducers:
            # Analyze address interactions
            if len(r['addresses']) > 1:
                state_changes['address_interaction_count'] = str(len(r['addresses']))
            
            # Analyze function call complexity
            function_counts = Counter(r['call_sequence'])
            state_changes['function_patterns'] = str(dict(function_counts.most_common(3)))
            
        return state_changes
    
    def _find_common_subsequences(self, sequences: List[List[str]]) -> List[List[str]]:
        """Find common subsequences in call patterns"""
        if not sequences:
            return []
            
        # Simple implementation: find sequences that appear in multiple reproducers
        sequence_counts = Counter()
        
        for seq in sequences:
            # Generate all subsequences of length 2-5
            for length in range(2, min(6, len(seq) + 1)):
                for i in range(len(seq) - length + 1):
                    subseq = tuple(seq[i:i+length])
                    sequence_counts[subseq] += 1
        
        # Return subsequences that appear in multiple cases
        common_sequences = []
        for subseq, count in sequence_counts.items():
            if count >= 2:  # Appears in at least 2 different reproducers
                common_sequences.append(list(subseq))
        
        return sorted(common_sequences, key=len, reverse=True)
    
    def _find_cross_property_patterns(self, reproducers: List[Dict]) -> List[VulnerabilityPattern]:
        """Find patterns that affect multiple properties"""
        patterns = []
        
        # Group by similar call sequences
        sequence_groups = defaultdict(list)
        for reproducer in reproducers:
            # Create a signature for the call sequence
            signature = tuple(reproducer['call_sequence'][:3])  # First 3 calls
            sequence_groups[signature].append(reproducer)
        
        # Look for groups that affect multiple properties
        for signature, group in sequence_groups.items():
            properties = set(r['failed_property'] for r in group if r['failed_property'])
            if len(properties) > 1:
                # This call sequence affects multiple properties
                pattern = VulnerabilityPattern(
                    pattern_id=f"cross_pattern_{hash(signature)}",
                    call_sequence=list(signature),
                    failed_properties=list(properties),
                    gas_consumption=[],
                    time_delays=[],
                    state_changes={},
                    frequency=len(group),
                    severity="HIGH",  # Cross-property issues are typically serious
                    description=f"Call sequence affects multiple properties: {', '.join(properties)}"
                )
                patterns.append(pattern)
        
        return patterns
    
    def _generate_pattern_description(self, property_name: str, functions: List[str], time_delays: List[int], pattern_type: str) -> str:
        """Generate human-readable description of vulnerability pattern"""
        
        base_descriptions = {
            'echidna_total_balance_conservation': 'Balance conservation violation',
            'echidna_constant_product': 'Constant product invariant violation',
            'echidna_no_arbitrary_minting': 'Unauthorized token minting',
            'echidna_price_bounds': 'Price manipulation beyond bounds',
            'echidna_time_consistency': 'Time consistency violation',
            'echidna_stake_consistency': 'Staking consistency violation'
        }
        
        base_desc = base_descriptions.get(property_name, f"Violation of {property_name}")
        
        # Add pattern type information
        pattern_descriptions = {
            'complex_transfer_manipulation': 'via complex transfer sequences',
            'defi_liquidity_manipulation': 'through liquidity manipulation',
            'temporal_logic_exploit': 'using time-dependent logic exploits',
            'state_corruption_sequence': 'via state corruption sequences'
        }
        
        pattern_desc = pattern_descriptions.get(pattern_type, '')
        
        # Add function information
        unique_functions = list(set(functions))
        if len(unique_functions) > 3:
            func_desc = f" involving {len(unique_functions)} functions: {', '.join(unique_functions[:3])}..."
        else:
            func_desc = f" involving: {', '.join(unique_functions)}"
        
        # Add time delay information
        if time_delays:
            max_delay = max(time_delays)
            if max_delay > 100000:  # Significant delays
                time_desc = f" with time manipulation (max delay: {max_delay})"
            else:
                time_desc = f" with timing: {len(time_delays)} delays"
        else:
            time_desc = ""
        
        return base_desc + (' ' + pattern_desc if pattern_desc else '') + func_desc + time_desc
    
    def _assess_severity(self, property_name: str, functions: List[str], frequency: int) -> str:
        """Assess the severity of a vulnerability pattern"""
        
        # Critical properties that indicate fund loss or major security issues
        critical_properties = [
            'echidna_total_balance_conservation',
            'echidna_no_arbitrary_minting',
            'echidna_constant_product'
        ]
        
        high_properties = [
            'echidna_price_bounds',
            'echidna_stake_consistency',
            'echidna_allowance_consistency'
        ]
        
        # Check for critical functions
        critical_functions = {'complexTransfer', 'addLiquidity', 'swap', 'mint', 'burn'}
        has_critical_functions = bool(set(functions) & critical_functions)
        
        if property_name in critical_properties or has_critical_functions:
            return "CRITICAL"
        elif property_name in high_properties or frequency > 1:
            return "HIGH"
        else:
            return "MEDIUM"
    
    def _assess_novelty(self, patterns: List[VulnerabilityPattern]) -> List[VulnerabilityPattern]:
        """Assess which patterns represent novel vulnerability classes"""
        novel_patterns = []
        
        for pattern in patterns:
            is_novel = self._is_novel_pattern(pattern)
            if is_novel:
                novel_patterns.append(pattern)
                print(f"üÜï Novel pattern discovered: {pattern.description}")
            else:
                print(f"üìã Known pattern: {pattern.description}")
        
        return novel_patterns
    
    def _is_novel_pattern(self, pattern: VulnerabilityPattern) -> bool:
        """Determine if a pattern represents a novel vulnerability class"""
        
        # Check against known vulnerability patterns
        description_lower = pattern.description.lower()
        
        # Simple keyword-based novelty assessment
        for known_vuln in self.known_vulns:
            if known_vuln in description_lower:
                return False
        
        # Check for novel characteristics
        novel_indicators = [
            'cross_pattern' in pattern.pattern_id,  # Cross-property patterns are often novel
            len(pattern.failed_properties) > 1,     # Multiple property violations
            pattern.frequency < 5,                  # Rare but reproducible
            'emergency' in description_lower and 'mode' in description_lower,  # Mode switching issues
            'metadata' in description_lower,        # Metadata manipulation
            'temporal' in description_lower and 'window' in description_lower  # Temporal logic issues
        ]
        
        return any(novel_indicators)
    
    def _rank_patterns(self, patterns: List[VulnerabilityPattern]) -> List[VulnerabilityPattern]:
        """Rank patterns by severity and potential impact"""
        
        severity_order = {"CRITICAL": 4, "HIGH": 3, "MEDIUM": 2, "LOW": 1}
        
        def pattern_score(pattern):
            severity_score = severity_order.get(pattern.severity, 0)
            frequency_score = min(pattern.frequency / 10, 1)  # Normalize frequency
            novelty_score = 2 if self._is_novel_pattern(pattern) else 1
            
            return severity_score * 10 + frequency_score * 5 + novelty_score * 3
        
        return sorted(patterns, key=pattern_score, reverse=True)
    
    def generate_report(self) -> str:
        """Generate a comprehensive vulnerability discovery report"""
        
        report = []
        report.append("# Novel Vulnerability Discovery Report")
        report.append(f"Generated on: {Path().cwd()}")
        report.append(f"Analysis of: {self.output_dir}")
        report.append("")
        
        if not self.patterns:
            report.append("‚ö†Ô∏è  No vulnerability patterns discovered. Consider:")
            report.append("- Running longer fuzzing campaigns")
            report.append("- Adjusting property definitions")
            report.append("- Testing with more diverse inputs")
            return "\n".join(report)
        
        report.append(f"## Summary")
        report.append(f"- **Total Patterns Found**: {len(self.patterns)}")
        
        severity_counts = Counter(p.severity for p in self.patterns)
        for severity, count in severity_counts.items():
            report.append(f"- **{severity}**: {count}")
        
        report.append("")
        report.append("## Detailed Findings")
        
        for i, pattern in enumerate(self.patterns, 1):
            report.append(f"### {i}. {pattern.description}")
            report.append(f"**Severity**: {pattern.severity}")
            report.append(f"**Frequency**: {pattern.frequency}")
            report.append(f"**Pattern ID**: {pattern.pattern_id}")
            
            if pattern.call_sequence:
                report.append(f"**Call Sequence**: {' -> '.join(pattern.call_sequence)}")
            
            if pattern.failed_properties:
                report.append(f"**Failed Properties**: {', '.join(pattern.failed_properties)}")
            
            report.append("")
        
        report.append("## Recommendations")
        report.append("1. **Immediate Actions**: Address CRITICAL and HIGH severity patterns")
        report.append("2. **Property Enhancement**: Add new Echidna properties based on findings")
        report.append("3. **Code Review**: Manual review of identified call sequences")
        report.append("4. **Testing Expansion**: Extend fuzzing to related contract functions")
        
        return "\n".join(report)
    
    def visualize_patterns(self):
        """Create visualizations of discovered patterns"""
        
        if not self.patterns:
            print("‚ö†Ô∏è  No patterns to visualize")
            return
        
        # Simple text-based visualization
        print("\n" + "="*60)
        print("VULNERABILITY PATTERN VISUALIZATION")
        print("="*60)
        
        # Severity distribution
        severity_counts = Counter(p.severity for p in self.patterns)
        print(f"\nSeverity Distribution:")
        for severity, count in severity_counts.items():
            bar = "‚ñà" * count
            print(f"  {severity:8}: {bar} ({count})")
        
        # Property violations
        all_properties = []
        for p in self.patterns:
            all_properties.extend(p.failed_properties)
        prop_counts = Counter(all_properties)
        
        if prop_counts:
            print(f"\nMost Violated Properties:")
            for prop, count in prop_counts.most_common(5):
                bar = "‚ñì" * count
                print(f"  {prop:25}: {bar} ({count})")
        
        print("="*60)

def main():
    """Main execution function"""
    if len(sys.argv) < 2:
        print("Usage: python vulnerability_discovery.py <echidna_output_directory>")
        print("Example: python vulnerability_discovery.py ./time-tests")
        sys.exit(1)
    
    output_dir = sys.argv[1]
    
    print("üîç Starting Novel Vulnerability Discovery Analysis...")
    analyzer = VulnerabilityDiscoveryAnalyzer(output_dir)
    
    # Run analysis
    patterns = analyzer.analyze_echidna_results()
    
    # Generate report
    report = analyzer.generate_report()
    
    # Save report
    report_file = Path(output_dir) / 'vulnerability_discovery_report.md'
    with open(report_file, 'w') as f:
        f.write(report)
    
    print(f"üìÑ Report saved to: {report_file}")
    
    # Print summary
    print("\n" + "="*60)
    print(report)
    
    # Create visualizations if patterns found
    if patterns:
        analyzer.visualize_patterns()

if __name__ == "__main__":
    main()
